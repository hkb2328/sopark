{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKazt0VIugHu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxv7w_2y2bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21cb191-d96c-4119-e519-df85a90c61ed"
      },
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [1 InRelease 0 B/129 kB \u001b[0m\u001b[33m\r0% [Waiting for headers] [Connected to cloud.r-project.org (108.157.173.89)] [C\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r                                                                               \rHit:3 https://cli.github.com/packages stable InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected\u001b[0m\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,008 kB]\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,535 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,157 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,498 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,839 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,870 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,597 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]\n",
            "Fetched 37.5 MB in 9s (4,153 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "58 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.12/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x788bc9b2eb10>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://da99a7bfb4f4:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our First Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## ðŸ“˜ **PySpark Joins â€“ Agenda**\n",
        "\n",
        "* Introduction to Joins in PySpark\n",
        "* Inner Join\n",
        "* Left Outer Join (Left Join)\n",
        "* Right Outer Join (Right Join)\n",
        "* Full Outer Join\n",
        "* Left Semi Join\n",
        "* Left Anti Join\n",
        "* Cross Join (Cartesian Product)\n",
        "* Self Join\n",
        "* Multiple Column Joins\n",
        "* Optimize JOins -> big vs Small and Big vs Big table\n",
        "* Broadcast Joins\n",
        "* Shuffle Hash Join\n",
        "* Sort Merge Join\n",
        "* Bucketing Starategy To load faster\n",
        "* Handling Null Values in Joins\n",
        "* Duplicate Column Names After Joins\n",
        "* Multiple Table Joins (Chaining Joins)\n",
        "* Conditional Joins (Non-Equi Joins)\n",
        "* Join Skew Problems and Solutions\n",
        "* Salting Technique for Skewed Joins\n",
        "* Adaptive Query Execution (AQE) for Joins\n",
        "* Join Hints and Strategies\n",
        "* Window Functions with Joins\n",
        "* Aggregations with Joins\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dTn4WyjC656G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = df1.join(df2,join_condation,join_type)\n",
        "\n",
        "df1 -> the left df\n",
        "df2 -> the right df\n",
        "join_condation : the column(s) to match\n",
        "join_tyep : the type of join to perform\n"
      ],
      "metadata": {
        "id": "iZWRSXi2_ImY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inner Join\n",
        "\n",
        "Returns only the rows where thers a match in both tables\n",
        "Both sides must match, NO match = not in result"
      ],
      "metadata": {
        "id": "vGZL02Uo_k0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AY2g-c8k_H_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers = spark.createDataFrame([\n",
        "    (1, \"Alice\"), (2, \"Bob\"), (3, \"Charlie\")\n",
        "], [\"cust_id\", \"name\"])\n",
        "\n",
        "customers.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSLg-xY6AfOR",
        "outputId": "684b3b7b-a110-43bd-80ea-4ac5c2f9b947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+\n",
            "|cust_id|   name|\n",
            "+-------+-------+\n",
            "|      1|  Alice|\n",
            "|      2|    Bob|\n",
            "|      3|Charlie|\n",
            "+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orders = spark.createDataFrame([\n",
        "    (101, 1, \"Laptop\"), (102, 2, \"Phone\"), (103, 5, \"Mouse\")\n",
        "], [\"order_id\", \"cust_id\", \"product\"])\n",
        "\n",
        "orders.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgjvL0-iAl5s",
        "outputId": "2c0948d4-9f62-476e-9781-1ec4fcbb185a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+-------+\n",
            "|order_id|cust_id|product|\n",
            "+--------+-------+-------+\n",
            "|     101|      1| Laptop|\n",
            "|     102|      2|  Phone|\n",
            "|     103|      5|  Mouse|\n",
            "+--------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=orders.join(customers,\"cust_id\",\"inner\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aozb-SIlAqqq",
        "outputId": "ef747ec6-b5bf-435e-c1ee-0556b491bb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+-----+\n",
            "|cust_id|order_id|product| name|\n",
            "+-------+--------+-------+-----+\n",
            "|      1|     101| Laptop|Alice|\n",
            "|      2|     102|  Phone|  Bob|\n",
            "+-------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import Return\n",
        "Left Outer Join (Left Join)\n",
        "\n",
        "Returns all rows from the left table and the matched rows from the right table\n",
        "if there is no match on the right side, null values are used"
      ],
      "metadata": {
        "id": "M_nJMxfSBV0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=customers.join(orders,\"cust_id\",\"left\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvnPZN5UCMI4",
        "outputId": "75847f54-10e1-4949-a3ba-a28ae615c26b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+--------+-------+\n",
            "|cust_id|   name|order_id|product|\n",
            "+-------+-------+--------+-------+\n",
            "|      1|  Alice|     101| Laptop|\n",
            "|      3|Charlie|    NULL|   NULL|\n",
            "|      2|    Bob|     102|  Phone|\n",
            "+-------+-------+--------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Right Outer Join (Right Join)\n",
        "\n",
        "returns all rows from the right table and the matched rows from the left table\n",
        "if there is no match on the left side, null values are used"
      ],
      "metadata": {
        "id": "Bi4UJSmjC12J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=customers.join(orders,\"cust_id\",\"right\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s2Dxw5FDD2l",
        "outputId": "62a57bf5-750d-4c51-92fe-0d21b9bacd77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+--------+-------+\n",
            "|cust_id| name|order_id|product|\n",
            "+-------+-----+--------+-------+\n",
            "|      1|Alice|     101| Laptop|\n",
            "|      5| NULL|     103|  Mouse|\n",
            "|      2|  Bob|     102|  Phone|\n",
            "+-------+-----+--------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Full Outer Join\n",
        "\n",
        "Returns all rows"
      ],
      "metadata": {
        "id": "jWFNLvzdDYJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=customers.join(orders,\"cust_id\",\"full\")\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRqZ1QxYDm9o",
        "outputId": "8221041a-cb32-4ede-ba52-2f8687c1389f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+--------+-------+\n",
            "|cust_id|   name|order_id|product|\n",
            "+-------+-------+--------+-------+\n",
            "|      1|  Alice|     101| Laptop|\n",
            "|      2|    Bob|     102|  Phone|\n",
            "|      3|Charlie|    NULL|   NULL|\n",
            "|      5|   NULL|     103|  Mouse|\n",
            "+-------+-------+--------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Left Semi Join\n",
        "\n",
        "left semi  join returns all rows from the left table and only\n",
        "the matched rows from the right table, but it does not include\n",
        "any data from the right table in the result -> it acts like\n",
        "a filter\n",
        "# if you want a unqiue left table rows then we can use left semi join"
      ],
      "metadata": {
        "id": "ria60jF5Dyux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers = spark.createDataFrame([\n",
        "    (1, \"Alice\"), (2, \"Bob\")\n",
        "], [\"cust_id\", \"name\"])\n",
        "\n",
        "orders = spark.createDataFrame([\n",
        "    (101, 1, \"Laptop\"), (102, 1, \"Mouse\"), (103, 2, \"Phone\")\n",
        "], [\"order_id\", \"cust_id\", \"product\"])\n",
        "\n",
        "print(\"LEFT SEMI JOIN:\")\n",
        "customers.join(orders, \"cust_id\", \"left_semi\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58V-I8GPE_dI",
        "outputId": "2a4121d5-9114-46c7-903f-b484096d3aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LEFT SEMI JOIN:\n",
            "+-------+-----+\n",
            "|cust_id| name|\n",
            "+-------+-----+\n",
            "|      1|Alice|\n",
            "|      2|  Bob|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers.join(orders, \"cust_id\", \"left\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "druzlvXSFO1l",
        "outputId": "6c73c4e6-bbcb-4172-a032-86653d2c7b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+--------+-------+\n",
            "|cust_id| name|order_id|product|\n",
            "+-------+-----+--------+-------+\n",
            "|      1|Alice|     102|  Mouse|\n",
            "|      1|Alice|     101| Laptop|\n",
            "|      2|  Bob|     103|  Phone|\n",
            "+-------+-----+--------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Left anti join\n",
        "\n",
        "Left anti join is the opposite of left semi join.\n",
        "It returns all rows from the left table where there is no match in the right table.\n",
        "its the exact opposit of left semi join  ->\n",
        "\n",
        "it finds whats missing"
      ],
      "metadata": {
        "id": "nm419SbyFvYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers = spark.createDataFrame([\n",
        "    (1, \"Alice\"), (2, \"Bob\"), (3, \"Charlie\"), (4, \"David\")\n",
        "], [\"cust_id\", \"name\"])\n",
        "\n",
        "# Orders DataFrame (RIGHT table - used only for filtering)\n",
        "orders = spark.createDataFrame([\n",
        "    (101, 1, \"Laptop\"), (102, 2, \"Phone\"), (103, 1, \"Mouse\")\n",
        "], [\"order_id\", \"cust_id\", \"product\"])\n",
        "\n",
        "customers.show()\n",
        "orders.show()\n",
        "\n",
        "result = customers.join(orders, \"cust_id\", \"left_anti\")\n",
        "result.show()\n",
        "\n",
        "result1 = customers.join(orders, \"cust_id\", \"left_semi\")\n",
        "result1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-MiBN-xGVjb",
        "outputId": "bbf4014d-bdf3-4064-c6e6-fc0b890a6e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+\n",
            "|cust_id|   name|\n",
            "+-------+-------+\n",
            "|      1|  Alice|\n",
            "|      2|    Bob|\n",
            "|      3|Charlie|\n",
            "|      4|  David|\n",
            "+-------+-------+\n",
            "\n",
            "+--------+-------+-------+\n",
            "|order_id|cust_id|product|\n",
            "+--------+-------+-------+\n",
            "|     101|      1| Laptop|\n",
            "|     102|      2|  Phone|\n",
            "|     103|      1|  Mouse|\n",
            "+--------+-------+-------+\n",
            "\n",
            "+-------+-------+\n",
            "|cust_id|   name|\n",
            "+-------+-------+\n",
            "|      3|Charlie|\n",
            "|      4|  David|\n",
            "+-------+-------+\n",
            "\n",
            "+-------+-----+\n",
            "|cust_id| name|\n",
            "+-------+-----+\n",
            "|      1|Alice|\n",
            "|      2|  Bob|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Join\n",
        "\n",
        "Returns the Cartesian product of the two DataFrames\n",
        "#"
      ],
      "metadata": {
        "id": "s9_nu2U1HMWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = spark.createDataFrame([\n",
        "    (\"Small\",), (\"Medium\",), (\"Large\",)\n",
        "], [\"size\"])\n",
        "\n",
        "colors = spark.createDataFrame([\n",
        "    (\"Red\",), (\"Blue\",)\n",
        "], [\"color\"])\n",
        "\n",
        "\n",
        "sizes.show()\n",
        "colors.show()\n",
        "\n",
        "result = sizes.crossJoin(colors)\n",
        "result.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiF78PRuHhaM",
        "outputId": "d24078a7-8109-444d-9709-5013ba7f5d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|  size|\n",
            "+------+\n",
            "| Small|\n",
            "|Medium|\n",
            "| Large|\n",
            "+------+\n",
            "\n",
            "+-----+\n",
            "|color|\n",
            "+-----+\n",
            "|  Red|\n",
            "| Blue|\n",
            "+-----+\n",
            "\n",
            "+------+-----+\n",
            "|  size|color|\n",
            "+------+-----+\n",
            "| Small|  Red|\n",
            "| Small| Blue|\n",
            "|Medium|  Red|\n",
            "| Large|  Red|\n",
            "|Medium| Blue|\n",
            "| Large| Blue|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# self JOin\n",
        "\n",
        "is when you jin a table with itself, you basicllay treat hte samae table as two\n",
        "seperate tables\n"
      ],
      "metadata": {
        "id": "7fKSKLKJUckA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Of5RR7SpLXXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SelfJoin\").getOrCreate()\n",
        "\n",
        "# Create employees DataFrame\n",
        "employees = spark.createDataFrame([\n",
        "    (1, \"Alice\", None),\n",
        "    (2, \"Bob\", 1),\n",
        "    (3, \"Charlie\", 1),\n",
        "    (4, \"David\", 2)\n",
        "], [\"emp_id\", \"emp_name\", \"manager_id\"])\n",
        "\n",
        "# Create aliases\n",
        "emp = employees.alias(\"emp\")\n",
        "mgr = employees.alias(\"mgr\")\n",
        "\n",
        "# Self Join using col() with qualified names\n",
        "result = emp.join(\n",
        "    mgr,\n",
        "    col(\"emp.manager_id\") == col(\"mgr.emp_id\"),\n",
        "    \"left\"\n",
        ").select(\n",
        "    col(\"emp.emp_id\").alias(\"employee_id\"),\n",
        "    col(\"emp.emp_name\").alias(\"employee_name\"),\n",
        "    col(\"mgr.emp_name\").alias(\"manager_name\")\n",
        ")\n",
        "\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiHz1S3hVJgO",
        "outputId": "9e11a232-ede0-45c8-a354-9c13465cfdf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+------------+\n",
            "|employee_id|employee_name|manager_name|\n",
            "+-----------+-------------+------------+\n",
            "|          1|        Alice|        NULL|\n",
            "|          2|          Bob|       Alice|\n",
            "|          3|      Charlie|       Alice|\n",
            "|          4|        David|         Bob|\n",
            "+-----------+-------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Multiple Column Joins\n",
        "\n",
        "when you join tables using more than one column as the\n",
        "match condations"
      ],
      "metadata": {
        "id": "BE6NTYXGVnW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"MultiColumnJoin\").getOrCreate()\n",
        "\n",
        "# Sales DataFrame\n",
        "sales = spark.createDataFrame([\n",
        "    (1, 101, \"Laptop\", 5),\n",
        "    (1, 102, \"Mouse\", 10),\n",
        "    (2, 101, \"Laptop\", 3),\n",
        "    (2, 103, \"Keyboard\", 7)\n",
        "], [\"store_id\", \"product_id\", \"product_name\", \"quantity_sold\"])\n",
        "\n",
        "# Inventory DataFrame\n",
        "inventory = spark.createDataFrame([\n",
        "    (1, 101, 50),\n",
        "    (1, 102, 100),\n",
        "    (2, 101, 30),\n",
        "    (3, 101, 20)\n",
        "], [\"store_id\", \"product_id\", \"stock\"])\n",
        "\n",
        "# Multiple Column Join - Match on BOTH store_id AND product_id\n",
        "result = sales.join(inventory, [\"store_id\", \"product_id\"], \"inner\")\n",
        "result.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZzNXTHpV3Wv",
        "outputId": "858193ce-6f7d-42ee-f3e8-9843bcbe6de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------------+-------------+-----+\n",
            "|store_id|product_id|product_name|quantity_sold|stock|\n",
            "+--------+----------+------------+-------------+-----+\n",
            "|       1|       101|      Laptop|            5|   50|\n",
            "|       1|       102|       Mouse|           10|  100|\n",
            "|       2|       101|      Laptop|            3|   30|\n",
            "+--------+----------+------------+-------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YO0dZtCyBVgy"
      }
    }
  ]
}